{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Esercitazione Pratica 1: Costruire un ChatBot ERP/CRM\n",
    "\n",
    "Implementiamo un chatbot interattivo che usa il nostro sistema RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot interattivo con memoria della conversazione\n",
    "class ERPCRMChatbot:\n",
    "    def __init__(self, rag_system):\n",
    "        self.rag = rag_system\n",
    "        self.conversation_history = []\n",
    "        \n",
    "    def add_to_history(self, role, content):\n",
    "        self.conversation_history.append({\"role\": role, \"content\": content})\n",
    "        # Mantieni solo ultimi 10 messaggi per evitare context troppo lungo\n",
    "        if len(self.conversation_history) > 10:\n",
    "            self.conversation_history = self.conversation_history[-10:]\n",
    "    \n",
    "    def chat(self, user_input):\n",
    "        # Aggiungi input utente alla storia\n",
    "        self.add_to_history(\"user\", user_input)\n",
    "        \n",
    "        # Determina se serve retrieval basandosi sull'input\n",
    "        needs_retrieval = any(keyword in user_input.lower() \n",
    "                            for keyword in ['come', 'cosa', 'quale', 'quando', 'perch√©', 'errore', 'problema'])\n",
    "        \n",
    "        if needs_retrieval:\n",
    "            # Usa RAG per domande tecniche\n",
    "            answer, sources = self.rag.query(user_input)\n",
    "            response = f\"{answer}\\n\\nüí° *Basato su documenti della knowledge base*\"\n",
    "        else:\n",
    "            # Conversazione generale\n",
    "            response = self.general_chat(user_input)\n",
    "        \n",
    "        self.add_to_history(\"assistant\", response)\n",
    "        return response\n",
    "    \n",
    "    def general_chat(self, user_input):\n",
    "        \"\"\"Gestisce conversazioni generali senza RAG\"\"\"\n",
    "        client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"\"\"Sei un assistente esperto in sistemi ERP e CRM. \n",
    "            Mantieni un tono professionale ma amichevole.\"\"\"}\n",
    "        ]\n",
    "        messages.extend(self.conversation_history)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "# Inizializza chatbot\n",
    "chatbot = ERPCRMChatbot(rag_system)\n",
    "\n",
    "# Simulazione chat\n",
    "print(\"ü§ñ Chatbot ERP/CRM pronto! Digita 'exit' per uscire.\\n\")\n",
    "\n",
    "test_conversations = [\n",
    "    \"Ciao! Sono nuovo in azienda e devo imparare ad usare SAP.\",\n",
    "    \"Come posso configurare il modulo HR?\",\n",
    "    \"Grazie! E per quanto riguarda l'integrazione con Salesforce?\",\n",
    "    \"Ho un errore 'Material not found', cosa posso fare?\"\n",
    "]\n",
    "\n",
    "for user_input in test_conversations:\n",
    "    print(f\"üë§ Tu: {user_input}\")\n",
    "    response = chatbot.chat(user_input)\n",
    "    print(f\"ü§ñ Bot: {response}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Esercitazione Pratica 2: Ottimizzazione e Metriche\n",
    "\n",
    "Implementiamo metriche per valutare la qualit√† del nostro sistema RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema di valutazione per RAG\n",
    "class RAGEvaluator:\n",
    "    def __init__(self, rag_system):\n",
    "        self.rag = rag_system\n",
    "        self.client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
    "        \n",
    "    def evaluate_retrieval_relevance(self, query, retrieved_contexts):\n",
    "        \"\"\"Valuta quanto i documenti recuperati sono rilevanti per la query\"\"\"\n",
    "        prompt = f\"\"\"Valuta la rilevanza del seguente contesto rispetto alla domanda.\n",
    "        Dai un punteggio da 1 a 5 dove:\n",
    "        1 = Completamente irrilevante\n",
    "        3 = Parzialmente rilevante\n",
    "        5 = Altamente rilevante\n",
    "        \n",
    "        Domanda: {query}\n",
    "        Contesto: {retrieved_contexts}\n",
    "        \n",
    "        Rispondi SOLO con il numero.\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            return int(response.choices[0].message.content.strip())\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def evaluate_answer_quality(self, query, answer, context):\n",
    "        \"\"\"Valuta la qualit√† della risposta generata\"\"\"\n",
    "        prompt = f\"\"\"Valuta la qualit√† della seguente risposta considerando:\n",
    "        - Accuratezza rispetto al contesto\n",
    "        - Completezza della risposta\n",
    "        - Utilit√† pratica\n",
    "        \n",
    "        Domanda: {query}\n",
    "        Contesto fornito: {context}\n",
    "        Risposta generata: {answer}\n",
    "        \n",
    "        Dai un punteggio da 1 a 5 e una breve motivazione.\n",
    "        Formato: SCORE: X - MOTIVAZIONE: ...\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def run_evaluation_suite(self, test_queries):\n",
    "        \"\"\"Esegue una suite completa di valutazione\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for query in test_queries:\n",
    "            # Retrieve context\n",
    "            context, sources = self.rag.retrieve_context(query)\n",
    "            \n",
    "            # Generate answer\n",
    "            answer = self.rag.generate_answer(query, context)\n",
    "            \n",
    "            # Evaluate\n",
    "            retrieval_score = self.evaluate_retrieval_relevance(query, context)\n",
    "            answer_evaluation = self.evaluate_answer_quality(query, answer, context)\n",
    "            \n",
    "            results.append({\n",
    "                'query': query,\n",
    "                'retrieval_score': retrieval_score,\n",
    "                'answer_evaluation': answer_evaluation,\n",
    "                'sources_count': len(sources)\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Inizializza evaluator\n",
    "evaluator = RAGEvaluator(rag_system)\n",
    "\n",
    "# Test queries per valutazione\n",
    "evaluation_queries = [\n",
    "    \"Come ottimizzare le query SOQL in Salesforce?\",\n",
    "    \"Quali sono i passaggi per configurare il modulo HR in SAP?\",\n",
    "    \"Come gestire gli errori di sincronizzazione tra SAP e Salesforce?\"\n",
    "]\n",
    "\n",
    "print(\"üîç Esecuzione valutazione del sistema RAG...\\n\")\n",
    "evaluation_results = evaluator.run_evaluation_suite(evaluation_queries)\n",
    "\n",
    "# Visualizza risultati\n",
    "for i, result in enumerate(evaluation_results):\n",
    "    print(f\"\\nQuery {i+1}: {result['query']}\")\n",
    "    print(f\"Retrieval Score: {'‚≠ê' * result['retrieval_score']} ({result['retrieval_score']}/5)\")\n",
    "    print(f\"Fonti trovate: {result['sources_count']}\")\n",
    "    print(f\"Valutazione risposta: {result['answer_evaluation']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Esercitazione Pratica 3: Gestione Multi-lingue\n",
    "\n",
    "Estendiamo il sistema per gestire documenti e query in multiple lingue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiungiamo documenti in italiano al nostro VectorDB\n",
    "italian_documents = [\n",
    "    {\n",
    "        \"id\": \"doc_it_1\",\n",
    "        \"text\": \"\"\"Procedura di chiusura mensile in SAP FI:\n",
    "        1. Eseguire transazione F.19 per riconciliazione GR/IR\n",
    "        2. Lanciare FAGLL03 per verifica movimenti contabili\n",
    "        3. Processare ammortamenti con AFAB\n",
    "        4. Chiudere periodi contabili in OB52\n",
    "        5. Generare report di chiusura con F.01\"\"\",\n",
    "        \"metadata\": {\n",
    "            \"module\": \"FI\", \n",
    "            \"system\": \"SAP\", \n",
    "            \"type\": \"procedure\",\n",
    "            \"language\": \"it\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_it_2\",\n",
    "        \"text\": \"\"\"Gestione lead qualificati in Salesforce:\n",
    "        Un lead √® considerato qualificato quando soddisfa i criteri BANT:\n",
    "        - Budget: ha budget allocato\n",
    "        - Authority: parla con decision maker\n",
    "        - Need: ha necessit√† identificata\n",
    "        - Timeline: tempistica definita\n",
    "        Utilizzare il pulsante 'Converti' per trasformare in Opportunit√†.\"\"\",\n",
    "        \"metadata\": {\n",
    "            \"module\": \"CRM\", \n",
    "            \"system\": \"Salesforce\", \n",
    "            \"type\": \"best_practice\",\n",
    "            \"language\": \"it\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Aggiungi documenti italiani a Pinecone\n",
    "vectors_it = []\n",
    "for doc in italian_documents:\n",
    "    embedding = create_embeddings([doc[\"text\"]])[0]\n",
    "    vectors_it.append({\n",
    "        \"id\": doc[\"id\"],\n",
    "        \"values\": embedding,\n",
    "        \"metadata\": {**doc[\"metadata\"], \"content\": doc[\"text\"][:200]}\n",
    "    })\n",
    "\n",
    "index.upsert(vectors=vectors_it)\n",
    "print(f\"‚úÖ Aggiunti {len(vectors_it)} documenti in italiano\")\n",
    "\n",
    "# Test query multilingue\n",
    "multilingual_queries = [\n",
    "    (\"Come fare la chiusura mensile in SAP?\", \"it\"),\n",
    "    (\"How to close the month in SAP?\", \"en\"),\n",
    "    (\"Cos'√® un lead qualificato?\", \"it\")\n",
    "]\n",
    "\n",
    "print(\"\\nüåç Test ricerca multilingue:\\n\")\n",
    "for query, lang in multilingual_queries:\n",
    "    results = semantic_search_pinecone(query, top_k=2)\n",
    "    print(f\"Query ({lang}): {query}\")\n",
    "    for match in results.matches:\n",
    "        print(f\"  - Score: {match.score:.3f} | Lang: {match.metadata.get('language', 'en')} | \"\n",
    "              f\"Module: {match.metadata.get('module')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Esercitazione Pratica 4: Hybrid Search\n",
    "\n",
    "Combiniamo ricerca vettoriale con filtri tradizionali per risultati pi√π precisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementazione Hybrid Search\n",
    "class HybridSearchEngine:\n",
    "    def __init__(self, pinecone_index, chroma_collection):\n",
    "        self.pinecone_index = pinecone_index\n",
    "        self.chroma_collection = chroma_collection\n",
    "        \n",
    "    def search(self, query, filters=None, use_pinecone=True, top_k=5):\n",
    "        \"\"\"Ricerca ibrida con supporto per filtri complessi\"\"\"\n",
    "        \n",
    "        if use_pinecone:\n",
    "            # Costruisci filtri Pinecone\n",
    "            pinecone_filter = self._build_pinecone_filter(filters)\n",
    "            results = semantic_search_pinecone(query, top_k=top_k, filter=pinecone_filter)\n",
    "            return self._format_pinecone_results(results)\n",
    "        else:\n",
    "            # Usa ChromaDB per query pi√π semplici\n",
    "            chroma_filter = self._build_chroma_filter(filters)\n",
    "            results = search_chromadb(query, n_results=top_k, filter_dict=chroma_filter)\n",
    "            return self._format_chroma_results(results)\n",
    "    \n",
    "    def _build_pinecone_filter(self, filters):\n",
    "        \"\"\"Costruisce filtri per Pinecone\"\"\"\n",
    "        if not filters:\n",
    "            return None\n",
    "            \n",
    "        pinecone_filter = {}\n",
    "        \n",
    "        # Filtri semplici\n",
    "        for key, value in filters.items():\n",
    "            if isinstance(value, list):\n",
    "                pinecone_filter[key] = {\"$in\": value}\n",
    "            else:\n",
    "                pinecone_filter[key] = value\n",
    "                \n",
    "        return pinecone_filter\n",
    "    \n",
    "    def _build_chroma_filter(self, filters):\n",
    "        \"\"\"Costruisce filtri per ChromaDB\"\"\"\n",
    "        if not filters:\n",
    "            return None\n",
    "            \n",
    "        # ChromaDB usa formato diverso per filtri\n",
    "        if len(filters) == 1:\n",
    "            key, value = list(filters.items())[0]\n",
    "            return {key: value}\n",
    "        else:\n",
    "            # Per filtri multipli\n",
    "            return {\"$and\": [{k: v} for k, v in filters.items()]}\n",
    "    \n",
    "    def _format_pinecone_results(self, results):\n",
    "        \"\"\"Formatta risultati Pinecone\"\"\"\n",
    "        formatted = []\n",
    "        for match in results.matches:\n",
    "            formatted.append({\n",
    "                'score': match.score,\n",
    "                'content': match.metadata.get('content', ''),\n",
    "                'metadata': match.metadata,\n",
    "                'source': 'pinecone'\n",
    "            })\n",
    "        return formatted\n",
    "    \n",
    "    def _format_chroma_results(self, results):\n",
    "        \"\"\"Formatta risultati ChromaDB\"\"\"\n",
    "        formatted = []\n",
    "        for i in range(len(results['documents'][0])):\n",
    "            formatted.append({\n",
    "                'score': 1 - results['distances'][0][i],  # Converti distanza in score\n",
    "                'content': results['documents'][0][i],\n",
    "                'metadata': results['metadatas'][0][i],\n",
    "                'source': 'chromadb'\n",
    "            })\n",
    "        return formatted\n",
    "\n",
    "# Inizializza Hybrid Search\n",
    "hybrid_search = HybridSearchEngine(index, collection)\n",
    "\n",
    "# Test con diversi filtri\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"configurazione moduli\",\n",
    "        \"filters\": {\"system\": \"SAP\"},\n",
    "        \"description\": \"Solo documenti SAP\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"integrazione sistemi\",\n",
    "        \"filters\": {\"type\": \"integration\"},\n",
    "        \"description\": \"Solo guide di integrazione\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"problemi performance\",\n",
    "        \"filters\": {\"module\": [\"CRM\", \"MM\"]},\n",
    "        \"description\": \"Solo moduli CRM o MM\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üîç Test Hybrid Search con filtri:\\n\")\n",
    "for test in test_cases:\n",
    "    print(f\"Query: '{test['query']}' - Filtro: {test['description']}\")\n",
    "    \n",
    "    # Test su Pinecone\n",
    "    results = hybrid_search.search(\n",
    "        test['query'], \n",
    "        filters=test['filters'], \n",
    "        use_pinecone=True,\n",
    "        top_k=3\n",
    "    )\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"  {i+1}. Score: {result['score']:.3f} | \"\n",
    "              f\"System: {result['metadata'].get('system', 'N/A')} | \"\n",
    "              f\"Type: {result['metadata'].get('type', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Best Practices e Ottimizzazioni\n",
    "\n",
    "Implementiamo alcune best practice per produzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring e logging per VectorDB\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class VectorDBMonitor:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            'queries': [],\n",
    "            'latencies': [],\n",
    "            'errors': []\n",
    "        }\n",
    "    \n",
    "    def log_query(self, query, latency, results_count, error=None):\n",
    "        \"\"\"Log delle metriche per ogni query\"\"\"\n",
    "        entry = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'query': query,\n",
    "            'latency_ms': latency * 1000,\n",
    "            'results_count': results_count,\n",
    "            'error': error\n",
    "        }\n",
    "        \n",
    "        self.metrics['queries'].append(entry)\n",
    "        self.metrics['latencies'].append(latency * 1000)\n",
    "        \n",
    "        if error:\n",
    "            self.metrics['errors'].append(entry)\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Calcola statistiche\"\"\"\n",
    "        if not self.metrics['latencies']:\n",
    "            return \"Nessuna query registrata\"\n",
    "        \n",
    "        return {\n",
    "            'total_queries': len(self.metrics['queries']),\n",
    "            'avg_latency_ms': np.mean(self.metrics['latencies']),\n",
    "            'p95_latency_ms': np.percentile(self.metrics['latencies'], 95),\n",
    "            'error_rate': len(self.metrics['errors']) / len(self.metrics['queries']),\n",
    "            'avg_results': np.mean([q['results_count'] for q in self.metrics['queries']])\n",
    "        }\n",
    "\n",
    "# Wrapper con monitoring\n",
    "monitor = VectorDBMonitor()\n",
    "\n",
    "def monitored_search(query, **kwargs):\n",
    "    \"\"\"Ricerca con monitoring delle performance\"\"\"\n",
    "    start_time = time.time()\n",
    "    error = None\n",
    "    results_count = 0\n",
    "    \n",
    "    try:\n",
    "        results = semantic_search_pinecone(query, **kwargs)\n",
    "        results_count = len(results.matches)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        raise\n",
    "    finally:\n",
    "        latency = time.time() - start_time\n",
    "        monitor.log_query(query, latency, results_count, error)\n",
    "\n",
    "# Test con monitoring\n",
    "test_queries_perf = [\n",
    "    \"Come configurare SAP HR?\",\n",
    "    \"Integrazione CRM con email\",\n",
    "    \"Troubleshooting performance issues\",\n",
    "    \"Best practices for sales pipeline\",\n",
    "    \"Ottimizzazione query database\"\n",
    "]\n",
    "\n",
    "print(\"‚è±Ô∏è  Test performance con monitoring:\\n\")\n",
    "for query in test_queries_perf:\n",
    "    results = monitored_search(query, top_k=3)\n",
    "    print(f\"Query: {query} - Risultati: {len(results.matches)}\")\n",
    "\n",
    "# Visualizza statistiche\n",
    "stats = monitor.get_stats()\n",
    "print(\"\\nüìä Statistiche performance:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value:.2f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Esercizio Finale: Sistema RAG Completo per ERP/CRM\n",
    "\n",
    "Mettiamo insieme tutti i componenti per creare un sistema production-ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprensione degli Embeddings\n",
    "\n",
    "Prima di usare i VectorDB, vediamo come funzionano gli embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di embeddings con OpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
    "\n",
    "# Testi di esempio dal dominio ERP/CRM\n",
    "texts = [\n",
    "    \"Il modulo CRM gestisce i contatti clienti e le opportunit√† di vendita\",\n",
    "    \"Sistema per amministrare relazioni con i customer e lead management\",\n",
    "    \"Report finanziario trimestrale con analisi del bilancio\",\n",
    "    \"Gestione ordini di acquisto e fatturazione fornitori nel modulo ERP\"\n",
    "]\n",
    "\n",
    "# Generazione embeddings\n",
    "def create_embeddings(texts):\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=texts\n",
    "    )\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "embeddings = create_embeddings(texts)\n",
    "\n",
    "print(f\"Dimensione embedding: {len(embeddings[0])}\")\n",
    "print(f\"Primi 10 valori del primo embedding: {embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo similarit√† tra embeddings\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Matrice di similarit√†\n",
    "print(\"Matrice di similarit√† tra i testi:\")\n",
    "print(\"\\nTesti:\")\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"{i}: {text[:50]}...\")\n",
    "\n",
    "print(\"\\nSimilarit√†:\")\n",
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        sim = cosine_similarity(embeddings[i], embeddings[j])\n",
    "        print(f\"Testo {i} vs Testo {j}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ChromaDB - Setup e operazioni base\n",
    "\n",
    "Iniziamo con ChromaDB per la sua semplicit√† in ambiente di sviluppo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Creazione client ChromaDB\n",
    "chroma_client = chromadb.Client(Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    "))\n",
    "\n",
    "# Creazione collection per documenti ERP\n",
    "collection_name = \"erp_crm_docs\"\n",
    "\n",
    "# Elimina collection se esiste gi√†\n",
    "try:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Collection '{collection_name}' creata con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documenti di esempio per knowledge base ERP/CRM\n",
    "erp_documents = [\n",
    "    {\n",
    "        \"id\": \"doc1\",\n",
    "        \"text\": \"\"\"Procedura di configurazione modulo HR in SAP:\n",
    "        1. Accedere alla transazione PA30 per gestione anagrafica dipendenti\n",
    "        2. Configurare infotipi base: 0000 (Azioni), 0001 (Assegnazione org), 0002 (Dati personali)\n",
    "        3. Impostare struttura organizzativa in PPOME\n",
    "        4. Definire aree del personale e sottoaree in SPRO\"\"\",\n",
    "        \"metadata\": {\"module\": \"HR\", \"system\": \"SAP\", \"type\": \"configuration\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc2\",\n",
    "        \"text\": \"\"\"Integrazione CRM Salesforce con sistema email:\n",
    "        1. Attivare Email-to-Case da Setup > Feature Settings\n",
    "        2. Configurare routing address per caselle email\n",
    "        3. Impostare regole di assignment per i case\n",
    "        4. Testare invio email a indirizzo routing\"\"\",\n",
    "        \"metadata\": {\"module\": \"CRM\", \"system\": \"Salesforce\", \"type\": \"integration\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc3\",\n",
    "        \"text\": \"\"\"Troubleshooting errore 'Material not found' in SAP MM:\n",
    "        Causa: Il materiale non esiste nel plant specificato\n",
    "        Soluzione: \n",
    "        1. Verificare in MM03 se il materiale esiste\n",
    "        2. Controllare estensione materiale al plant corretto\n",
    "        3. Se mancante, estendere con MM01 selezionando viste necessarie\"\"\",\n",
    "        \"metadata\": {\"module\": \"MM\", \"system\": \"SAP\", \"type\": \"troubleshooting\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc4\",\n",
    "        \"text\": \"\"\"Best practice per gestione pipeline vendite in CRM:\n",
    "        1. Definire stadi chiari: Prospect > Qualified > Proposal > Negotiation > Closed\n",
    "        2. Assegnare probabilit√† di chiusura per ogni stadio\n",
    "        3. Implementare criteri di avanzamento oggettivi\n",
    "        4. Monitorare tempo medio per stadio\n",
    "        5. Configurare alert per opportunit√† ferme\"\"\",\n",
    "        \"metadata\": {\"module\": \"CRM\", \"system\": \"Generic\", \"type\": \"best_practice\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Aggiunta documenti a ChromaDB\n",
    "collection.add(\n",
    "    documents=[doc[\"text\"] for doc in erp_documents],\n",
    "    metadatas=[doc[\"metadata\"] for doc in erp_documents],\n",
    "    ids=[doc[\"id\"] for doc in erp_documents]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Aggiunti {len(erp_documents)} documenti alla collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query su ChromaDB\n",
    "def search_chromadb(query, n_results=3, filter_dict=None):\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results,\n",
    "        where=filter_dict\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Test query semplice\n",
    "query = \"Come configurare permessi utente HR?\"\n",
    "results = search_chromadb(query)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Risultati:\")\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results['documents'][0], \n",
    "    results['metadatas'][0],\n",
    "    results['distances'][0]\n",
    ")):\n",
    "    print(f\"\\n{i+1}. Distanza: {distance:.3f}\")\n",
    "    print(f\"   Modulo: {metadata['module']} - Sistema: {metadata['system']}\")\n",
    "    print(f\"   Testo: {doc[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query con filtri\n",
    "query_filtered = \"problemi di configurazione\"\n",
    "results_sap = search_chromadb(\n",
    "    query_filtered, \n",
    "    filter_dict={\"system\": \"SAP\"}\n",
    ")\n",
    "\n",
    "print(f\"Query: {query_filtered} (solo documenti SAP)\\n\")\n",
    "print(\"Risultati filtrati:\")\n",
    "for i, (doc, metadata) in enumerate(zip(\n",
    "    results_sap['documents'][0], \n",
    "    results_sap['metadatas'][0]\n",
    ")):\n",
    "    print(f\"\\n{i+1}. {metadata['module']} - {metadata['type']}\")\n",
    "    print(f\"   {doc[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pinecone - Setup per produzione\n",
    "\n",
    "Pinecone √® pi√π adatto per ambienti di produzione con alta scalabilit√†."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Inizializzazione Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Nome dell'index\n",
    "index_name = \"erp-crm-knowledge\"\n",
    "\n",
    "# Elimina index se esiste\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# Crea nuovo index\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1536,  # dimensione embeddings OpenAI\n",
    "    metric='cosine',\n",
    "    spec=ServerlessSpec(\n",
    "        cloud='aws',\n",
    "        region='us-east-1'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Connessione all'index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "print(f\"‚úÖ Index Pinecone '{index_name}' creato con successo!\")\n",
    "print(f\"Statistiche index: {index.describe_index_stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparazione documenti per Pinecone con chunking\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Documenti pi√π lunghi per dimostrare chunking\n",
    "long_documents = [\n",
    "    {\n",
    "        \"title\": \"Guida completa integrazione SAP-Salesforce\",\n",
    "        \"content\": \"\"\"L'integrazione tra SAP ERP e Salesforce CRM √® fondamentale per sincronizzare \n",
    "        i dati tra i due sistemi. Il processo inizia con la mappatura dei campi tra i due sistemi.\n",
    "        \n",
    "        FASE 1 - Analisi e Mappatura:\n",
    "        Prima di iniziare l'integrazione, √® necessario mappare i campi tra SAP e Salesforce.\n",
    "        Ad esempio, il Business Partner in SAP corrisponde all'Account in Salesforce.\n",
    "        I materiali in SAP devono essere mappati ai Product in Salesforce.\n",
    "        \n",
    "        FASE 2 - Configurazione Middleware:\n",
    "        Si consiglia l'uso di SAP PI/PO o Dell Boomi come middleware.\n",
    "        Configurare i web service in SAP usando transaction SOAMANAGER.\n",
    "        In Salesforce, creare Connected App per l'autenticazione OAuth.\n",
    "        \n",
    "        FASE 3 - Sincronizzazione dati:\n",
    "        Implementare logica di sincronizzazione bidirezionale per:\n",
    "        - Clienti/Account\n",
    "        - Ordini di vendita\n",
    "        - Fatture\n",
    "        - Stato consegne\n",
    "        \n",
    "        FASE 4 - Gestione errori:\n",
    "        Implementare logging dettagliato e meccanismi di retry.\n",
    "        Configurare alert per sincronizzazioni fallite.\n",
    "        Prevedere riconciliazione manuale per conflitti.\"\"\",\n",
    "        \"metadata\": {\"type\": \"integration_guide\", \"systems\": [\"SAP\", \"Salesforce\"]}\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Ottimizzazione performance query CRM\",\n",
    "        \"content\": \"\"\"Le performance delle query nel CRM possono degradare con l'aumento dei dati.\n",
    "        Ecco le best practice per mantenere prestazioni ottimali.\n",
    "        \n",
    "        ANALISI DELLE QUERY LENTE:\n",
    "        1. Attivare il debug log per identificare query SOQL lente\n",
    "        2. Usare Developer Console per analizzare execution plan\n",
    "        3. Identificare missing indexes tramite Query Plan Tool\n",
    "        \n",
    "        OTTIMIZZAZIONE INDICI:\n",
    "        - Creare custom indexes sui campi pi√π filtrati\n",
    "        - Evitare query su campi non indicizzati\n",
    "        - Usare indexed fields nelle WHERE clause\n",
    "        \n",
    "        BEST PRACTICE SOQL:\n",
    "        - Limitare campi selezionati (no SELECT *)\n",
    "        - Usare LIMIT appropriati\n",
    "        - Evitare nested queries quando possibile\n",
    "        - Implementare lazy loading per related records\n",
    "        \n",
    "        ARCHITETTURA SCALABILE:\n",
    "        - Implementare caching strategy con Platform Cache\n",
    "        - Usare asynchronous processing per operazioni pesanti\n",
    "        - Considerare data archiving per record storici\"\"\",\n",
    "        \"metadata\": {\"type\": \"performance_guide\", \"module\": \"CRM\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configurazione text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Chunking e preparazione per Pinecone\n",
    "vectors_to_upsert = []\n",
    "\n",
    "for doc in long_documents:\n",
    "    chunks = text_splitter.split_text(doc[\"content\"])\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Crea embedding per chunk\n",
    "        embedding = create_embeddings([chunk])[0]\n",
    "        \n",
    "        # Prepara vettore per Pinecone\n",
    "        vector_id = f\"{doc['title']}_chunk_{i}\"\n",
    "        metadata = doc[\"metadata\"].copy()\n",
    "        metadata[\"chunk_index\"] = i\n",
    "        metadata[\"title\"] = doc[\"title\"]\n",
    "        metadata[\"content\"] = chunk[:200]  # preview del contenuto\n",
    "        \n",
    "        vectors_to_upsert.append({\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": metadata\n",
    "        })\n",
    "\n",
    "# Upsert in batch\n",
    "index.upsert(vectors=vectors_to_upsert)\n",
    "\n",
    "print(f\"‚úÖ Inseriti {len(vectors_to_upsert)} chunks in Pinecone\")\n",
    "print(f\"Statistiche index: {index.describe_index_stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di ricerca semantica con Pinecone\n",
    "def semantic_search_pinecone(query, top_k=5, filter=None):\n",
    "    # Crea embedding per la query\n",
    "    query_embedding = create_embeddings([query])[0]\n",
    "    \n",
    "    # Esegui ricerca\n",
    "    results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        filter=filter,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test ricerca\n",
    "query = \"Come ottimizzare le performance delle query nel CRM?\"\n",
    "results = semantic_search_pinecone(query, top_k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Risultati:\")\n",
    "for i, match in enumerate(results.matches):\n",
    "    print(f\"\\n{i+1}. Score: {match.score:.3f}\")\n",
    "    print(f\"   Titolo: {match.metadata.get('title', 'N/A')}\")\n",
    "    print(f\"   Tipo: {match.metadata.get('type', 'N/A')}\")\n",
    "    print(f\"   Preview: {match.metadata.get('content', 'N/A')}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementazione Sistema RAG Completo\n",
    "\n",
    "Ora integriamo il VectorDB con un LLM per creare un sistema RAG funzionante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe RAG per ERP/CRM Knowledge Base\n",
    "class ERPCRMKnowledgeRAG:\n",
    "    def __init__(self, index_name=\"erp-crm-knowledge\"):\n",
    "        self.pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "        self.index = self.pc.Index(index_name)\n",
    "        self.client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
    "        \n",
    "    def retrieve_context(self, query, top_k=5, filter=None):\n",
    "        \"\"\"Recupera documenti rilevanti dal VectorDB\"\"\"\n",
    "        # Embedding della query\n",
    "        query_embedding = create_embeddings([query])[0]\n",
    "        \n",
    "        # Ricerca nel VectorDB\n",
    "        results = self.index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=top_k,\n",
    "            filter=filter,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        \n",
    "        # Estrai contesto dai risultati\n",
    "        contexts = []\n",
    "        sources = []\n",
    "        \n",
    "        for match in results.matches:\n",
    "            if match.score > 0.7:  # threshold di rilevanza\n",
    "                contexts.append(match.metadata.get('content', ''))\n",
    "                sources.append({\n",
    "                    'title': match.metadata.get('title', 'Unknown'),\n",
    "                    'score': match.score\n",
    "                })\n",
    "        \n",
    "        return \"\\n\\n\".join(contexts), sources\n",
    "    \n",
    "    def generate_answer(self, query, context, system_prompt=None):\n",
    "        \"\"\"Genera risposta usando il contesto recuperato\"\"\"\n",
    "        if not system_prompt:\n",
    "            system_prompt = \"\"\"Sei un esperto consulente ERP/CRM. \n",
    "            Rispondi alle domande basandoti ESCLUSIVAMENTE sul contesto fornito.\n",
    "            Se il contesto non contiene informazioni sufficienti, indicalo chiaramente.\n",
    "            Fornisci risposte pratiche e actionable.\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"Contesto:\n",
    "{context}\n",
    "\n",
    "Domanda: {query}\n",
    "\n",
    "Risposta:\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def query(self, question, filter=None):\n",
    "        \"\"\"Pipeline RAG completa\"\"\"\n",
    "        # 1. Retrieve\n",
    "        context, sources = self.retrieve_context(question, filter=filter)\n",
    "        \n",
    "        if not context:\n",
    "            return \"Mi dispiace, non ho trovato informazioni rilevanti nella knowledge base.\", []\n",
    "        \n",
    "        # 2. Generate\n",
    "        answer = self.generate_answer(question, context)\n",
    "        \n",
    "        return answer, sources\n",
    "\n",
    "# Inizializzazione sistema RAG\n",
    "rag_system = ERPCRMKnowledgeRAG()\n",
    "print(\"‚úÖ Sistema RAG inizializzato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test del sistema RAG con domande reali\n",
    "test_questions = [\n",
    "    \"Come posso migliorare le performance delle query nel CRM?\",\n",
    "    \"Quali sono i passaggi per integrare SAP con Salesforce?\",\n",
    "    \"Come risolvo l'errore 'Material not found' in SAP?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìù DOMANDA: {question}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    answer, sources = rag_system.query(question)\n",
    "    \n",
    "    print(f\"\\nüí° RISPOSTA:\\n{answer}\")\n",
    "    \n",
    "    if sources:\n",
    "        print(f\"\\nüìö FONTI:\")\n",
    "        for source in sources:\n",
    "            print(f\"   - {source['title']} (score: {source['score']:.3f})\")"
   ]
  }
 ]